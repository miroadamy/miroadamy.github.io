<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>devops on Miro&#39;s World</title>
    <link>https://miroadamy.com/categories/devops/</link>
    <description>Recent content in devops on Miro&#39;s World</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 12 May 2020 22:34:38 +0800</lastBuildDate>
    
	<atom:link href="https://miroadamy.com/categories/devops/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using SSH keys with multiple Bitbucket accounts</title>
      <link>https://miroadamy.com/posts/2020-05-12-bitbucket-keys/</link>
      <pubDate>Tue, 12 May 2020 22:34:38 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2020-05-12-bitbucket-keys/</guid>
      <description>I have been using Bitbucket since 2012, long before my company moved from in-house hosted server running Gitolite and in-house instances of FishEye and Crucible to cloud based source control on Bitbucket Cloud. As legacy I was using my personal login with my gmail account as my Bitbucket identity.
With merge of 3 companies in 2018 and rebranding as Pivotree, we are in process of streamlining the identity management and using SSO for identification.</description>
    </item>
    
    <item>
      <title>History of Faith</title>
      <link>https://miroadamy.com/posts/2020-03-31-history-of-faith/</link>
      <pubDate>Tue, 31 Mar 2020 11:24:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2020-03-31-history-of-faith/</guid>
      <description>The beginnings Once upon a time - actually, in late 2017-early 2018 - there was a QA/DevOps engineer named José who liked containers, Docker and worked for a company named Thinkwrap (that soon would become Pivotree) in Valencia, Spain.
José was responsible (among other things) for setting up integration and QA environments for multiple Hybris projects. Such environment, when being built in traditional way (from physical servers or VMs), normally requires quite a few pieces:</description>
    </item>
    
    <item>
      <title>Kubectl client and server version mismatch</title>
      <link>https://miroadamy.com/posts/2020-01-19-kubectl-version/</link>
      <pubDate>Sun, 19 Jan 2020 11:12:38 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2020-01-19-kubectl-version/</guid>
      <description>Accessing Rancher cluster I was doing update on Kubernetes cluster I had not touch in a while when I noticed weird behaviour:
 the output of get command was incomplete the -o wide option had no effect on the command output  (IP addresses are masked)
➜ .kube git:(master) ✗ kubectl --kubeconfig dropship-dev-uat get nodes NAME AGE ip-172-xx-xx-xx.ca-central-1.compute.internal 613d ip-172-xx-xx-xx.ca-central-1.compute.internal 628d ip-172-xx-xx-xx.ca-central-1.compute.internal 558d and
➜ .kube git:(master) ✗ kubectl --kubeconfig dropship-dev-uat get nodes -o wide NAME AGE ip-172-xx-xx-xx.</description>
    </item>
    
    <item>
      <title>Rancher CLI vs kubectl</title>
      <link>https://miroadamy.com/posts/2020-01-18-rancher-cli/</link>
      <pubDate>Sat, 18 Jan 2020 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2020-01-18-rancher-cli/</guid>
      <description>Accessing Rancher cluster After creation, you can access the K8s cluster running Rancher by saving the config file available from the console and using standard kubectl command
kubectl --kubeconfig ./quickstart.kubeconfig get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE cattle-system cattle-cluster-agent-5c98cb979f-bbhxf 1/1 Running 0 5d23h cattle-system cattle-node-agent-dwnxk 1/1 Running 0 5d23h cattle-system kube-api-auth-d4zgq 1/1 Running 0 5d23h ingress-nginx default-http-backend-67cf578fc4-grmsw 1/1 Running 0 5d23h ingress-nginx nginx-ingress-controller-mpnmb 1/1 Running 0 5d23h kube-system canal-jw85q 2/2 Running 0 5d23h kube-system coredns-5c59fd465f-47q5z 1/1 Running 0 5d23h kube-system coredns-autoscaler-d765c8497-sm5xf 1/1 Running 0 5d23h kube-system metrics-server-64f6dffb84-bp864 1/1 Running 0 5d23h kube-system rke-coredns-addon-deploy-job-95qnk 0/1 Completed 0 5d23h kube-system rke-ingress-controller-deploy-job-brv7w 0/1 Completed 0 5d23h kube-system rke-metrics-addon-deploy-job-tvt89 0/1 Completed 0 5d23h kube-system rke-network-plugin-deploy-job-7rqcr 0/1 Completed 0 5d23h The same information (and much more) is available using rancher CLI.</description>
    </item>
    
    <item>
      <title>On harvesting credit card numbers and passwords</title>
      <link>https://miroadamy.com/posts/2019-12-11-hackernoon/</link>
      <pubDate>Wed, 11 Dec 2019 21:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-12-11-hackernoon/</guid>
      <description>This is the scariest thing I have read since spring 2018:
https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5
written by @david.gilbertson.
It pretty sure what he describes is actually happening, has been happening before he described it and will be happening going on - just obviously not in the named module. The ecosystem of Node modules is so vast and so unstable that considerable number of project do not do enough to catch behaviour like this.</description>
    </item>
    
    <item>
      <title>Building Hugo as well on GitLab pages</title>
      <link>https://miroadamy.com/posts/2019-11-23-gitlab-hugo/</link>
      <pubDate>Sat, 23 Nov 2019 22:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-11-23-gitlab-hugo/</guid>
      <description>Parallel building challenges Unlike Github, Gitlab considers Hugo blogs first class citizens and does not impose any restrictions on repo naming.
I had 3 challenges to overcome related to co-existence of GH and GL versions:
 I need to use same repo for both GH and GL the submodule link for public does not work on GL the site root is different - I have no custom domain forward for GitLab  Using same repo To separate the GH and GL, I have added 2 remotes to repo and special branch gitlab-pages.</description>
    </item>
    
    <item>
      <title>Current Hugo setup on Github Pages</title>
      <link>https://miroadamy.com/posts/2019-11-22-hugo-setup/</link>
      <pubDate>Fri, 22 Nov 2019 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-11-22-hugo-setup/</guid>
      <description>How does the blog setup and publishing work Before I forget, here is how the current configuration works.
There are two repositories at play:
 source repo - https://github.com/miroadamy/miroadamy.com github pages repo (== GHPR) - https://github.com/miroadamy/miroadamy.github.io  The blog source repo contains only source files (.md, static media etc). This repo has usual submodules under the /themes - e.g. /themes/even which is one currently used.
The Githup pages repo contains generated static site, with index.</description>
    </item>
    
    <item>
      <title>From Jekyll to Hugo</title>
      <link>https://miroadamy.com/posts/2019-11-20-from-jekyll-to-hugo/</link>
      <pubDate>Wed, 20 Nov 2019 23:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-11-20-from-jekyll-to-hugo/</guid>
      <description>I have decided to consolidate all piecemeal versions of my blogpost uder one roof and at the same to do these four things
 technology upgrade - from Jekyll to Hugo visual refresh of the page review tagging and categorization merge hidden posts from Wikis to one place  Why Hugo replaced Jekyll The version 3 of my blog (see below for a bit of history) has been hosted on Github pages and using the default static site generators - Jekyll.</description>
    </item>
    
    <item>
      <title>All Day DevOps 2019</title>
      <link>https://miroadamy.com/posts/2019-11-07-all-day-devops/</link>
      <pubDate>Thu, 07 Nov 2019 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-11-07-all-day-devops/</guid>
      <description>All Day DevOps 2019 - Notes I have attended the All Day Devops - https://www.alldaydevops.com/ on 06 Nov 2019 - an event that runs for 24 hours and has multiple tracks of content organized in 4 blocks.
The tracks:
 Keynotes Cultural Change DevSecOps SRE CI/CD Everything Cloud  The complete list is here: https://www.alldaydevops.com/2019-live-schedule - the play button points to the block video.
The Video URLs Channel 1  https://www.</description>
    </item>
    
    <item>
      <title>AWS Inspection</title>
      <link>https://miroadamy.com/posts/2019-10-03-aws-inspection/</link>
      <pubDate>Thu, 03 Oct 2019 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-10-03-aws-inspection/</guid>
      <description>Bunch of one-liners for AWS .. so that I find them faster next time
aws --output=json ec2 describe-instances | jq -r &amp;#39;.Reservations[].Instances[] | &amp;#34;\n&amp;#34; + .InstanceId + &amp;#34; : &amp;#34; + .KeyName + &amp;#34; =&amp;gt; &amp;#34; + .PublicIpAddress + &amp;#34; | &amp;#34; + .PublicDnsName, .Tags[] as $tt | &amp;#34; ... &amp;#34; + $tt.Key +&amp;#34;:&amp;#34;+ $tt.Value&amp;#39; aws ec2 describe-instances | jq &amp;#39;.Reservations[].Instances[] | .InstanceId + &amp;#34; : &amp;#34; + .Placement.AvailabilityZone + &amp;#34; =&amp;gt; &amp;#34; + .</description>
    </item>
    
    <item>
      <title>Gitbits</title>
      <link>https://miroadamy.com/posts/2019-01-14-gitbits/</link>
      <pubDate>Mon, 14 Jan 2019 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2019-01-14-gitbits/</guid>
      <description>Two small utilities I have places into ~/bin:
git-attic Source: https://github.com/maximeh/dotfiles/blob/master/common/.bin/git-attic
#!/bin/sh # git-attic [-M] [PATH] - list deleted files of Git repositories # # Use -M to not show renamed files, and other git-log options as you like. git log --raw --no-renames --date=short --format=&amp;#34;%h %cd&amp;#34; &amp;#34;$@&amp;#34; | awk &amp;#39;/^[0-9a-f]/ { commit=$1; date=$2 } /^:/ &amp;amp;&amp;amp; $5 == &amp;#34;D&amp;#34; { print date, commit &amp;#34;^:&amp;#34; $6 }&amp;#39; | less Example ➜ kubernetes-the-hard-way git:(master) ✗ git log --raw --no-renames --date=short --format=&amp;#34;%h %cd&amp;#34; &amp;#34;$@&amp;#34; | awk &amp;#39;/^[0-9a-f]/ { commit=$1; date=$2 } /^:/ &amp;amp;&amp;amp; $5 == &amp;#34;D&amp;#34; { print date, commit &amp;#34;^:&amp;#34; $6 }&amp;#39; 2019-11-20 374e8d9^:docs/using-rst/pdp-template-rst.</description>
    </item>
    
    <item>
      <title>AWS Certified Developer - Associate</title>
      <link>https://miroadamy.com/posts/2018-11-28-aws/</link>
      <pubDate>Sun, 28 Oct 2018 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2018-11-28-aws/</guid>
      <description>Got the second certification today
https://www.certmetrics.com/amazon/public/badge.aspx?i=2&amp;amp;t=c&amp;amp;d=2018-11-28&amp;amp;ci=AWS00261816</description>
    </item>
    
    <item>
      <title>Useful tool for Dockerhub</title>
      <link>https://miroadamy.com/posts/2018-10-24-dockerhub-tool/</link>
      <pubDate>Wed, 24 Oct 2018 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2018-10-24-dockerhub-tool/</guid>
      <description>Skopeo I have stumbled upon this tool: https://github.com/containers/skopeo - command line tools for manipulation with Docker images and Docker image registries.
It can work with OCI images as well as the original Docker v2 images.
Installation brew install skopeo Usage ➜ deploy-2018-10-24 skopeo --override-os=linux inspect docker://docker.io/fedora { &amp;#34;Name&amp;#34;: &amp;#34;docker.io/library/fedora&amp;#34;, &amp;#34;Digest&amp;#34;: &amp;#34;sha256:b41cd083421dd7aa46d619e958b75a026a5d5733f08f14ba6d53943d6106ea6d&amp;#34;, &amp;#34;RepoTags&amp;#34;: [ &amp;#34;20&amp;#34;, &amp;#34;21&amp;#34;, &amp;#34;22&amp;#34;, &amp;#34;23&amp;#34;, &amp;#34;24&amp;#34;, &amp;#34;25&amp;#34;, &amp;#34;26-modular&amp;#34;, &amp;#34;26&amp;#34;, &amp;#34;27&amp;#34;, &amp;#34;28&amp;#34;, &amp;#34;29&amp;#34;, &amp;#34;branched&amp;#34;, &amp;#34;heisenbug&amp;#34;, &amp;#34;latest&amp;#34;, &amp;#34;modular&amp;#34;, &amp;#34;rawhide&amp;#34; ], &amp;#34;Created&amp;#34;: &amp;#34;2018-09-07T19:20:02.</description>
    </item>
    
    <item>
      <title>AWS Certified Solution Architect - Associate</title>
      <link>https://miroadamy.com/posts/2018-06-07-aws/</link>
      <pubDate>Thu, 07 Jun 2018 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2018-06-07-aws/</guid>
      <description>Step 1 done.
https://www.certmetrics.com/amazon/public/badge.aspx?i=1&amp;amp;t=c&amp;amp;d=2018-06-06&amp;amp;ci=AWS00261816&amp;amp;fbclid=IwAR2K8B4FyKWVstBZXCXn5GhYX9iRyB4U2q8l2ROrM_16m-rlclioalnp0O4
And now dilemma: go deeper into AWS or look around what Google and Azure have to offer ?
So many clouds, so little time &amp;hellip;</description>
    </item>
    
    <item>
      <title>Blog of the day - Tapas Forever</title>
      <link>https://miroadamy.com/posts/2018-06-03-botd/</link>
      <pubDate>Thu, 07 Jun 2018 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2018-06-03-botd/</guid>
      <description>Fellow Canadian describes his path to Spain
https://tapasforever.com/</description>
    </item>
    
    <item>
      <title>Creating Kubernetes Cluster in AWS from scratch with kops</title>
      <link>https://miroadamy.com/posts/2018-05-07-k8s-from-scratch-kops/</link>
      <pubDate>Mon, 07 May 2018 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2018-05-07-k8s-from-scratch-kops/</guid>
      <description>This describes creation of K8s cluster in AWS environment from scratch as done for microservices based eCommerce project.
Pre-requisites  AWS account access - IAM with Admin privileges AWS CLI installed - https://docs.aws.amazon.com/cli/latest/userguide/cli-install-macos.html CLI credentials (secret key + api Key) - https://docs.aws.amazon.com/cli/latest/reference/iam/index.html Kubectl and Kops local install ** see https://github.com/kubernetes/kops and https://kubernetes.io/docs/tasks/tools/install-kubectl/  Test of access ➜ etc git:(feature/kubernetes) aws --version aws-cli/1.11.180 Python/3.6.4 Darwin/17.5.0 botocore/1.7.38 ➜ etc git:(feature/kubernetes) kubectl version Client Version: version.</description>
    </item>
    
    <item>
      <title>VisualVM inside Docker container</title>
      <link>https://miroadamy.com/posts/2017-11-23-visual-vm/</link>
      <pubDate>Thu, 23 Nov 2017 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2017-11-23-visual-vm/</guid>
      <description>The idea / motivation In order to run VisualVM from predefined configuration you need to point the app to the user directory. This directory takes about 20MB, but 90% of the the content is actually generated or repeated.
➜ 4devops-visualvm git:(master) du -sh tw-sl/* 244K tw-sl/config 7.3M tw-sl/modules 52K tw-sl/repository 4.0K tw-sl/update 104K tw-sl/update_tracking 11M tw-sl/var ➜ 4devops-visualvm git:(master) du -sh tw-wool/* 248K tw-wool/config 7.2M tw-wool/modules 60K tw-wool/repository 4.0K tw-wool/update 104K tw-wool/update_tracking 11M tw-wool/var ➜ 4devops-visualvm git:(master) du -sh tw-wool 19M tw-wool The only part that is specific and worthy of maintaining in the Git repo is repository</description>
    </item>
    
    <item>
      <title>Install AWS CLI on Mac</title>
      <link>https://miroadamy.com/posts/2017-11-14-install-aws-cli-mac/</link>
      <pubDate>Tue, 14 Nov 2017 14:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2017-11-14-install-aws-cli-mac/</guid>
      <description>Install AWS CLI on Mac The Mac comes with Python 2.7 and no pip
This guide recommends upgrade to Python 3 which I want to avoid: http://docs.aws.amazon.com/cli/latest/userguide/cli-install-macos.html
Unsuccesfull path - keep the Python 2.7 ➜ ~ pip --version zsh: command not found: pip ➜ ~ sudo easy_install pip Password: Searching for pip Reading https://pypi.python.org/simple/pip/ Best match: pip 9.0.1 Downloading https://pypi.python.org/packages/11/b6/abcb525026a4be042b486df43905d6893fb04f05aac21c32c638e939e447/pip-9.0.1.tar.gz#md5=35f01da33009719497f01a4ba69d63c9 Processing pip-9.0.1.tar.gz Writing /tmp/easy_install-QnLLJp/pip-9.0.1/setup.cfg Running pip-9.0.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-QnLLJp/pip-9.0.1/egg-dist-tmp-03hMh7 /System/Library/Frameworks/Python.</description>
    </item>
    
    <item>
      <title>Storing sensitive information in Git</title>
      <link>https://miroadamy.com/posts/2017-05-15-sensitive-git/</link>
      <pubDate>Wed, 17 May 2017 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2017-05-15-sensitive-git/</guid>
      <description>The purpose of this is to evaluate options and suggest possible approaches for handling the sensitive information in Git repositories such as database credentials, API credentials, passwords, keys, certificates etc. Joel asked this question a few weeks ago - this is part of Milos&amp;rsquo;s security awareness program.
The issue Git repos store in cleartext all credentials, that may also be including PROD credentials.
Everybody who clones the repository - every developer has access to this information that should have been shared only with the support team that has legitimate access to production.</description>
    </item>
    
    <item>
      <title>Managing code in remote SVN repo</title>
      <link>https://miroadamy.com/posts/2017-05-10-remote-svn/</link>
      <pubDate>Wed, 10 May 2017 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2017-05-10-remote-svn/</guid>
      <description>This is based on J.&amp;lsquo;s&amp;rsquo; question in Slack:
 Do we have some customer where we are moving a git repo to svn in an automated fashion I just need to move the git repo into svn periodically nightly
 The setup (as I understand it):
 on client side we have a worktree that is Git repository the files needs to be copied to SVN regularly  Options Use git-svn bridge Git client allows to &amp;ldquo;pretend&amp;rdquo; it is SVN and pull/push against remote SVN repo</description>
    </item>
    
    <item>
      <title>Process for transferring Git repo from Gitolite to Bitbucket</title>
      <link>https://miroadamy.com/posts/2016-11-02-pensieve-to-bitbucket/</link>
      <pubDate>Wed, 02 Nov 2016 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-11-02-pensieve-to-bitbucket/</guid>
      <description>Task Transfer full Git history (all branches, tags, etc) to Bitbucket so that development can continue from there
User setup  List all keys in Gitolite must have access to Gitolite admin interface  cd $ADMIN_HOME/pensieve/PRJ-admin/gitolite-admin ➜ gitolite-admin git:(master) ll keydir total 144K -rw-r--r-- 1 miro 401 Jun 29 2015 alter.pub -rw-r--r-- 1 miro 397 Jun 29 2015 codereview.pub -rw-r--r-- 1 miro 400 Apr 18 2016 hybris.pub -rw-r--r-- 1 miro 400 Apr 19 2016 hybris2.</description>
    </item>
    
    <item>
      <title>Update all local branches in Git repo</title>
      <link>https://miroadamy.com/posts/2016-09-05-git-update-all-local-branches/</link>
      <pubDate>Mon, 05 Sep 2016 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-09-05-git-update-all-local-branches/</guid>
      <description>Update all local branches in Git repo Issue: The git pull updates just one current branch.
In DevOps I am following many Git repos and need to keep up to date for all local branches.
git ffwd-update command Source: http://stackoverflow.com/questions/4318161/can-git-pull-all-update-all-my-local-branches
Create file named git-ffwd-update somewhere on the path (in my case ~/bin)
#!/bin/bash  main() { REMOTES=&amp;#34;$@&amp;#34;; if [ -z &amp;#34;$REMOTES&amp;#34; ]; then REMOTES=$(git remote); fi REMOTES=$(echo &amp;#34;$REMOTES&amp;#34; | xargs -n1 echo) CLB=$(git branch -l|awk &amp;#39;/^\*/{print $2}&amp;#39;); echo &amp;#34;$REMOTES&amp;#34; | while read REMOTE; do git remote update $REMOTE git remote show $REMOTE -n \  | awk &amp;#39;/merges with remote/{print $5&amp;#34; &amp;#34;$1}&amp;#39; \  | while read line; do RB=$(echo &amp;#34;$line&amp;#34;|cut -f1 -d&amp;#34; &amp;#34;); ARB=&amp;#34;refs/remotes/$REMOTE/$RB&amp;#34;; LB=$(echo &amp;#34;$line&amp;#34;|cut -f2 -d&amp;#34; &amp;#34;); ALB=&amp;#34;refs/heads/$LB&amp;#34;; NBEHIND=$(( $(git rev-list --count $ALB.</description>
    </item>
    
    <item>
      <title>Learning resources for Linux and Command line</title>
      <link>https://miroadamy.com/posts/2016-05-30-linux-resources/</link>
      <pubDate>Mon, 30 May 2016 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-05-30-linux-resources/</guid>
      <description>This quick summary to answer Megha Maiya&amp;rsquo;s question - I am adding to the Wiki in case it can be expanded later useful for somebody else:
 expanded later useful for somebody else  Free resources There is HUGE amount of resources available for Linux and Unix out there. The issue is select those reasonably good
 List of lists: https://github.com/learnbyexample/scripting_course/blob/master/Linux_curated_resources.md http://ryanstutorials.net/, specially http://ryanstutorials.net/linuxtutorial/ and http://ryanstutorials.net/linuxtutorial/ http://www.tutorialspoint.com/unix/unix-getting-started.htm (bash scripting) - https://bash.</description>
    </item>
    
    <item>
      <title>Native OS-X Docker (Beta) - not quite there yet</title>
      <link>https://miroadamy.com/posts/2016-05-17-docker-osx/</link>
      <pubDate>Tue, 17 May 2016 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-05-17-docker-osx/</guid>
      <description>I was intrigued by convenience of using Docker natively on Mac, without dealing with differences localhost != dockerhost, so I subscribed for Beta and installed it.
Good news 1 It can coexist with previous Docker installation (mostly) - see the note at the end. As long as you do not try to run native Docker and docker-machine at the same time, things coexist.
Good news 2 It works for several images I tried.</description>
    </item>
    
    <item>
      <title>Starting ACC (ATG Control Centre) on OS-X</title>
      <link>https://miroadamy.com/posts/2016-03-24-acc-on-osx/</link>
      <pubDate>Thu, 24 Mar 2016 12:57:35 -0500</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-03-24-acc-on-osx/</guid>
      <description>Copy the installation of ACC for respective version from a Linux VM:
The startup script in bin/startClient will fail, because it cannot determine which Java to use to run the app.
It is trying to determine Unix flavour, failing that defaults to Solaris and ends up with invalid settings.
Fix Set the variable JAVA_VM to path to executable command on your system.
which java java is /Library/Java/JavaVirtualMachines/jdk1.7.0_55.jdk/Contents/Home/bin/java java is /usr/bin/java export JAVA_VM=/Library/Java/JavaVirtualMachines/jdk1.</description>
    </item>
    
    <item>
      <title>Fixing docker-machine error after upgrade</title>
      <link>https://miroadamy.com/posts/2016-03-16-docker-machine-error-after-upgrade/</link>
      <pubDate>Wed, 16 Mar 2016 12:57:35 -0500</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-03-16-docker-machine-error-after-upgrade/</guid>
      <description>I had to upgrade docker toolbox on Yosemite to get latest docker-compose additions.
After installing the new package, I was not able to connect to docker machine:
➜ ~ docker-machine status Stopped ➜ ~ docker-machine start default Starting &amp;#34;default&amp;#34;... (default) Check network to re-create if needed... (default) Waiting for an IP... Machine &amp;#34;default&amp;#34; was started. Waiting for SSH to be available... Detecting the provisioner... Started machines may have new IP addresses.</description>
    </item>
    
    <item>
      <title>Accessing internal AWS servers directly from Mac</title>
      <link>https://miroadamy.com/posts/2016-02-18-access-aws-servers/</link>
      <pubDate>Thu, 18 Feb 2016 00:57:35 -0500</pubDate>
      
      <guid>https://miroadamy.com/posts/2016-02-18-access-aws-servers/</guid>
      <description>Motivation for this hack is my unwillingness to suffer the pain of using Windows UI just to access BCC, ACC or other ATG tools requiring non command-line interface.
The credit for finding out about approach is blog post by James McOrmond - VPN over SSH - who is using this neat trick from Linux for quite some time.
The software mentioned https://github.com/apenwarr/sshuttle supposedly works on OS-X, however, it has not been updated for 4-5 years and would not function for me (OS-X Yosemite).</description>
    </item>
    
    <item>
      <title>Docker - getting started</title>
      <link>https://miroadamy.com/posts/2015-12-11-docker-starting/</link>
      <pubDate>Fri, 11 Dec 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-12-11-docker-starting/</guid>
      <description>After the reboot docker version Client: Version: 1.9.1 API version: 1.21 Go version: go1.4.3 Git commit: a34a1d5 Built: Fri Nov 20 17:56:04 UTC 2015 OS/Arch: darwin/amd64 Cannot connect to the Docker daemon. Is the docker daemon running on this host? ➜ gitolite-admin git:(master) docker-machine active No active host found ➜ gitolite-admin git:(master) docker-machine env default Error checking TLS connection: default is not running. Please start it in order to use the connection settings ➜ gitolite-admin git:(master) docker-machine start Error: Expected to get one or more machine names as arguments ➜ gitolite-admin git:(master) docker-machine start default (default) Starting VM.</description>
    </item>
    
    <item>
      <title>Starting ACC in VM</title>
      <link>https://miroadamy.com/posts/2015-07-15-acc-in-vm/</link>
      <pubDate>Wed, 15 Jul 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-07-15-acc-in-vm/</guid>
      <description>The ACC is installed in default location: ~/ATG/ACC11.1
This does not work OOTB. You must set 2 additional ENV properties
cd ~/ATG/ACC11.0 export ACC_HOME=`pwd` export JAVA_VM=/usr/java/jdk1.7.0_51//bin/java bin/startClient &amp;amp; Starting from dyn/admin The start in separate VM works OK.
Start in server VM brings errors message very often complaining of malformed Help URL. The issue is documented here: http://stackoverflow.com/questions/20868244/how-to-fix-malformed-help-url-while-opening-acc-atg - for JBOSS.
I tried to add the protocol.jar from DAS/lib into Tomcat lib, but it made no difference.</description>
    </item>
    
    <item>
      <title>How to truncate Git history</title>
      <link>https://miroadamy.com/posts/2015-15-07-git-history/</link>
      <pubDate>Tue, 14 Jul 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-15-07-git-history/</guid>
      <description>The general idea #!/bin/bash # Parameter: tag or sha1 git checkout --orphan temp $1 git commit -m &amp;#34;Truncated history&amp;#34; git rebase --onto temp $1 master git branch -D temp Requires Git 1.8+
Works well for mostly linear history (aka Git used for diff-ing of the catalog feeds).
How it works Starting repo (training):
➜ test git:(master) git last fe4e396 2015-07-13 | Fix for BuildInfo in TDD, database connectivity works (HEAD, origin/dynamovies/main, master) [Miro Adamy] f1b8636 2015-07-13 | Tables and database creation [Miro Adamy] d4c182b 2015-07-13 | Added template of dynamovies module - with empty UI.</description>
    </item>
    
    <item>
      <title>How to get information about all ATG components</title>
      <link>https://miroadamy.com/posts/2015-07-12-component-report/</link>
      <pubDate>Sun, 12 Jul 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-07-12-component-report/</guid>
      <description>How to get information about all ATG Nucleus components Dyn Admin has useful feature - Configuration reporter: http://localhost:8080/dyn/admin/atg/dynamo/admin/en/config-reporter-property-representation1.jhtml
There are two variations of the report: Property representation report - PRR (shorter version) and Bean representation report (BRR). The PRR does not report properties that have default values, while BRR is reporting current values of all properties. Compare the sizes
-rw-r--r-- 1 miro 2.2M Jul 12 14:07 bean1 -rw-r--r-- 1 miro 2.</description>
    </item>
    
    <item>
      <title>How to fix Jenkins build issues related to Git connectivity</title>
      <link>https://miroadamy.com/posts/2015-06-18-jenkins-git/</link>
      <pubDate>Thu, 18 Jun 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-06-18-jenkins-git/</guid>
      <description>Symptoms:  build fails cannot checkout / connect to GIT  Validate this is the case  ssh to jenkins2 assume identity of jenkins user (VERY IMPORTANT) go to /home/projects/workspace/PROJECTNAME directory  This directory is repository clone. Try &amp;lsquo;git status&amp;rsquo; in that directory. If you see something like
-bash-3.2$ git status fatal: unable to read tree 2d0456480112e9f9a8508bb47dc3863112cc6253 the git repo is corrupted and needs to be reloaded.
Step 1 - Get the remote repo URL -bash-3.</description>
    </item>
    
    <item>
      <title>How to solve &#39;Agent admitted failure to sign using the key&#39;</title>
      <link>https://miroadamy.com/posts/2015-05-22-ssh-issue/</link>
      <pubDate>Fri, 22 May 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-05-22-ssh-issue/</guid>
      <description>After re-creating the SSH key, I got the above error from Gitolite.
Full trace:
➜ TWC ssh -v thinkwrap@pensieve.thinkwrap.com OpenSSH_5.3p1, OpenSSL 1.0.1e-fips 11 Feb 2013 debug1: Reading configuration data /etc/ssh/ssh_config debug1: Applying options for * debug1: Connecting to pensieve.thinkwrap.com [24.137.198.18] port 22. debug1: Connection established. debug1: identity file /home/thinkwrap/.ssh/identity type -1 debug1: identity file /home/thinkwrap/.ssh/identity-cert type -1 debug1: identity file /home/thinkwrap/.ssh/id_rsa type 1 debug1: identity file /home/thinkwrap/.ssh/id_rsa-cert type -1 debug1: identity file /home/thinkwrap/.</description>
    </item>
    
    <item>
      <title>Fixing the shutdown problem with JBoss</title>
      <link>https://miroadamy.com/posts/2015-04-11-jboss-shutdown/</link>
      <pubDate>Sat, 11 Apr 2015 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2015-04-11-jboss-shutdown/</guid>
      <description>Observed at QA environment. During automated shutdown sequence, the exception was thrown:
$ bin/gdi-qa-com1.sh stop JBOSS_CMD_STOP = java -classpath /opt/jboss/jboss-as/bin/shutdown.jar:/opt/jboss/jboss-as/client/jnet.jar org.jboss.Shutdown --shutdown --user=admin --password=admin -s jnp://0.0.0.0:1099 Exception in thread &amp;#34;main&amp;#34; javax.naming.CommunicationException: Could not obtain connection to any of these urls: 0.0.0.0:1099 [Root exception is javax.naming.CommunicationException: Failed to connect to server /0.0.0.0:1099 [Root exception is javax.naming.ServiceUnavailableException: Failed to connect to server /0.0.0.0:1099 [Root exception is java.net.ConnectException: Connection refused]]] at org.jnp.interfaces.NamingContext.checkRef(NamingContext.java:1763) at org.</description>
    </item>
    
    <item>
      <title>ATG Repository structure visualizer</title>
      <link>https://miroadamy.com/posts/2014-11-04-atg-repo-visualizer/</link>
      <pubDate>Tue, 04 Nov 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-11-04-atg-repo-visualizer/</guid>
      <description>The groovy script does parse the XML files (scraped from dyn-admin, or output of the XML combine) and produces file in the syntax of Plant UML - http://plantuml.sourceforge.net
if (args.size() == 0) { println &amp;#34;Usage: groovy extractItems.groovy XMLFILE-IN-GSA-FORMAT.xml&amp;#34; System.exit(1) } def gsaFile = new XmlSlurper().parseText(new File(args[0]).text) def desc = gsaFile.&amp;#39;item-descriptor&amp;#39; def processItemDescriptor(myDesc) { def info = [:] def tables = [] def props = [:] def descriptors = [:] for (table in myDesc.</description>
    </item>
    
    <item>
      <title>Dealing with &#39;Java Runtime SE 6&#39; required error</title>
      <link>https://miroadamy.com/posts/2014-10-14-java6required/</link>
      <pubDate>Tue, 14 Oct 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-10-14-java6required/</guid>
      <description>When trying to start DBeaver (http://dbeaver.jkiss.org) I got this
I do have Java 7 installed:
➜ Contents java -version java version &amp;#34;1.7.0_55&amp;#34; Java(TM) SE Runtime Environment (build 1.7.0_55-b13) Java HotSpot(TM) 64-Bit Server VM (build 24.55-b03, mixed mode) ➜ Contents which java java is /Library/Java/JavaVirtualMachines/jdk1.7.0_55.jdk/Contents/Home/bin/java java is /usr/bin/java which should be a superset. But it is not.
Solution Oracle seems to screw up the PLIST capabilities in JAva7 install
Go to</description>
    </item>
    
    <item>
      <title>Gitbits - Get committer lists</title>
      <link>https://miroadamy.com/posts/2014-09-29-gitbits/</link>
      <pubDate>Mon, 29 Sep 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-09-29-gitbits/</guid>
      <description>With emails (Unix only) ➜ dev1 git:(miro-ui) ✗ git log --raw | grep &amp;#34;^Author: &amp;#34; | sort | uniq -c 9 Author: Brendan Smith &amp;lt;Brendan.Smith@thinkwrap.com&amp;gt; 22 Author: Kai Cheng &amp;lt;kai.cheng@thinkwrap.com&amp;gt; 97 Author: Miro Adamy &amp;lt;miro.adamy@thinkwrap.com&amp;gt; 49 Author: Training VM &amp;lt;training-vm@thinkwrap.com&amp;gt; 24 Author: Your Name &amp;lt;your.name@thinkwrap.com&amp;gt; Pure git ➜ dev1 git:(miro-ui) ✗ git shortlog -sen 97 Miro Adamy &amp;lt;miro.adamy@thinkwrap.com&amp;gt; 49 Training VM &amp;lt;training-vm@thinkwrap.com&amp;gt; 24 Your Name &amp;lt;your.name@thinkwrap.com&amp;gt; 22 Kai Cheng &amp;lt;kai.cheng@thinkwrap.com&amp;gt; 9 Brendan Smith &amp;lt;Brendan.</description>
    </item>
    
    <item>
      <title>How to access shared folder in Linux guest in VirtualBox</title>
      <link>https://miroadamy.com/posts/2014-09-23-shared-folder/</link>
      <pubDate>Tue, 23 Sep 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-09-23-shared-folder/</guid>
      <description>Make sure the VBOx extensions are installed.
Go here for details:
Add share In VirtualBox, Device add transient shared folder:
This one has made available path /Users/Shared/ATG-11 under the name ATG-11
Mount it sudo mount -t vboxsf ATG-11 /media $ ll /media/Unix/ total 19M drwxr-xr-x. 1 root 408 Sep 12 16:02 ATG11-1 drwxr-xr-x. 1 root 272 Sep 12 16:02 ATG11-docs -rw-rw-r--. 1 root 675 May 13 23:46 atg-platform-mac.userlibraries -rw-rw-r--. 1 root 787 May 13 23:17 atg-platform-vm.</description>
    </item>
    
    <item>
      <title>logstash - known error</title>
      <link>https://miroadamy.com/posts/2014-09-16-logstash-error/</link>
      <pubDate>Tue, 16 Sep 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-09-16-logstash-error/</guid>
      <description>I have been trying to make this work for about 1.5 hr. Looks like there is open bug - https://logstash.jira.com/browse/LOGSTASH-703
Helpful link: https://groups.google.com/forum/#!topic/logstash-users/sZM03po7HJE
What should work:
grok { match =&amp;gt; [&amp;#34;message&amp;#34;, &amp;#34;regex to parse severity&amp;#34;], match =&amp;gt; [&amp;#34;message&amp;#34;, &amp;#34;regex to parse server IP&amp;#34;], match =&amp;gt; [&amp;#34;message&amp;#34;, &amp;#34;regex to parse user&amp;#34;] } What needs to be done instead
You _should_ be able to do exactly what you listed at the bottom of your email, except that you&amp;#39;d need `break_on_match =&amp;gt; false` so that it would parse each snippet for each message instead of just parsing the first one that matches.</description>
    </item>
    
    <item>
      <title>Recreate txt base graph generator</title>
      <link>https://miroadamy.com/posts/2014-09-09-redo-graph/</link>
      <pubDate>Tue, 09 Sep 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-09-09-redo-graph/</guid>
      <description>Graphviz This time using brew
➜ DPS brew install graphviz ==&amp;gt; Downloading https://downloads.sf.net/project/machomebrew/Bottles/graphviz-2.38.0.mavericks.bottle.tar.gz ######################################################################## 100.0% ==&amp;gt; Pouring graphviz-2.38.0.mavericks.bottle.tar.gz 🍺 /usr/local/Cellar/graphviz/2.38.0: 469 files, 68M ➜ DPS dot -V dot - graphviz version 2.38.0 (20140413.2041) ➜ DPS Schema Spy From http://sourceforge.net/projects/schemaspy/files/schemaspy/SchemaSpy%205.0.0/
To /opt/diagram
Run:
 diagram java -jar ./schemaSpy_5.0.0.jar -cp .:/Users/miro/lib/jdbc/mysql-connector-java-5.1.26-bin.jar -t mysql -o library -host localhost -u training -db training_dev01 -p training
 It produces HTML documentation for tables
Size is about 51 M for a small ATG install</description>
    </item>
    
    <item>
      <title>Better dynadmin</title>
      <link>https://miroadamy.com/posts/2014-09-04-better-dynadmin/</link>
      <pubDate>Thu, 04 Sep 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-09-04-better-dynadmin/</guid>
      <description>Source of the fix is https://github.com/jc7447/BetterDynAdmin. This is to capture the installation process and provide backup in case the tool disappears.
The pages generated by DynAdmin are actually not coming from a JSP or JHTML pages. The HTML you see is generated by hardcoded servlets. Each Nucleus component has assigned Admin servet, which is called when DynAdmin is trying to render the page.
The improvent here are user scripts - running inside Firefox or Chrome, utilizing infrastructure provided by Greasemonkey extension (FF) or Tampermonkey (Chrome).</description>
    </item>
    
    <item>
      <title>Tutorial on Elastic</title>
      <link>https://miroadamy.com/posts/2014-08-28-elastic-tutorial/</link>
      <pubDate>Thu, 28 Aug 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-08-28-elastic-tutorial/</guid>
      <description>Running elastic (see Elastic search and Kibana - getting started)
 Use case: building a employee directory for Megacorp
  each document - type of &amp;lsquo;employee&amp;rsquo; everything in megacorp index  Populating # Delete the `megacorp` index in case it already exists DELETE /megacorp # Index document 1, type &amp;#34;employee&amp;#34;, in the # &amp;#34;megacorp&amp;#34; index PUT /megacorp/employee/1 { &amp;#34;first_name&amp;#34; : &amp;#34;John&amp;#34;, &amp;#34;last_name&amp;#34; : &amp;#34;Smith&amp;#34;, &amp;#34;age&amp;#34; : 25, &amp;#34;about&amp;#34; : &amp;#34;I love to go rock climbing&amp;#34;, &amp;#34;interests&amp;#34;: [ &amp;#34;sports&amp;#34;, &amp;#34;music&amp;#34; ] } # Index two more documents PUT /megacorp/employee/2 { &amp;#34;first_name&amp;#34; : &amp;#34;Jane&amp;#34;, &amp;#34;last_name&amp;#34; : &amp;#34;Smith&amp;#34;, &amp;#34;age&amp;#34; : 32, &amp;#34;about&amp;#34; : &amp;#34;I like to collect rock albums&amp;#34;, &amp;#34;interests&amp;#34;: [ &amp;#34;music&amp;#34; ] } PUT /megacorp/employee/3 { &amp;#34;first_name&amp;#34; : &amp;#34;Douglas&amp;#34;, &amp;#34;last_name&amp;#34; : &amp;#34;Fir&amp;#34;, &amp;#34;age&amp;#34; : 35, &amp;#34;about&amp;#34;: &amp;#34;I like to build cabinets&amp;#34;, &amp;#34;interests&amp;#34;: [ &amp;#34;forestry&amp;#34; ] } In server</description>
    </item>
    
    <item>
      <title>Elastic search and Kibana - getting started</title>
      <link>https://miroadamy.com/posts/2014-08-27-es1/</link>
      <pubDate>Wed, 27 Aug 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-08-27-es1/</guid>
      <description>#Installation:
See 
curl -L -O http://download.elasticsearch.org/PATH/TO/VERSION.zip unzip elasticsearch-$VERSION.zip cd elasticsearch-$VERSION Marvel is management plugin - console about cluster. Install:
./bin/plugin -i elasticsearch/marvel/latest # disable data collection for local cluster echo &amp;#39;marvel.agent.enabled: false&amp;#39; &amp;gt;&amp;gt; ./config/elasticsearch.yml Test Startup log:
➜ elasticsearch-1.3.2 bin/elasticsearch [2014-08-27 11:17:08,325][INFO ][node ] [Joe Fixit] version[1.3.2], pid[59610], build[dee175d/2014-08-13T14:29:30Z] [2014-08-27 11:17:08,325][INFO ][node ] [Joe Fixit] initializing ... [2014-08-27 11:17:08,338][INFO ][plugins ] [Joe Fixit] loaded [marvel], sites [marvel, kopf] [2014-08-27 11:17:10,905][INFO ][marvel.</description>
    </item>
    
    <item>
      <title>Finding out the class in ATG installation</title>
      <link>https://miroadamy.com/posts/2014-08-26-find-class/</link>
      <pubDate>Tue, 26 Aug 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-08-26-find-class/</guid>
      <description>Java approach Use the real time search with this JAR - https://jarscan.com/
➜ scripts git:(authoring) ✗ java -jar ~/bin/jarscan.jar ========================= JarScan written by Geoff Yaworski gyaworski@hotmail.com Version 2.0 ========================= Usage: java -jar jarscan.jar [-help | /?] [-dir directory name] [-zip] [-showProgress] &amp;lt;-files | -class | -package&amp;gt; &amp;lt;search string 1&amp;gt; [search string 2] [search string n] Help: -help or /? Displays this message. -dir The directory to start searching from default is &amp;#34;.</description>
    </item>
    
    <item>
      <title>How to install Chrome in Centos 6.5</title>
      <link>https://miroadamy.com/posts/2014-04-04-install-chrome-centos6/</link>
      <pubDate>Fri, 04 Apr 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-04-04-install-chrome-centos6/</guid>
      <description>How to install Chrome in Centos 6.5 Step 1. Add Google Yum Repository Create a new yum repository using below instructions.
 sudo vim /etc/yum.repos.d/google.repo
Add following content to this file
[google] name=Google baseurl=http://dl.google.com/linux/rpm/stable/$basearch enabled=1 gpgcheck=1 gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub Step 2: Install/Update Google Chrome Richard Lloid provided an shell script to grab libraries from a more recent Linux distro, put them in a tree (/opt/google/chrome/lib) exclusively picked up by Google Chrome and then you can indeed run Google Chrome on CentOS 6.</description>
    </item>
    
    <item>
      <title>Gitolite permissions setup</title>
      <link>https://miroadamy.com/posts/2014-04-02-gitolite-permissions/</link>
      <pubDate>Wed, 02 Apr 2014 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2014-04-02-gitolite-permissions/</guid>
      <description>This documents how to enforce the Gitolite permission to make LIVE branch writeable only by team leads
How gitolite works Repository permission structure This is general format of repo definition
REPO NAME rule line rule line for example
@staff = dilbert alice wally bob repo foo RW+ = dilbert # line 1 RW+ dev = alice # line 2 - = wally # line 3 RW temp/ = @staff # line 4 R = ashok # line 5 The Rule line has format:</description>
    </item>
    
    <item>
      <title>Difference between matching and simple Git push</title>
      <link>https://miroadamy.com/posts/2013-12-31-difference-between-matching-and-simple-git-push/</link>
      <pubDate>Tue, 31 Dec 2013 16:41:38 -0500</pubDate>
      
      <guid>https://miroadamy.com/posts/2013-12-31-difference-between-matching-and-simple-git-push/</guid>
      <description>I started to see this message in some of my Git environments
Git 2.0 from &amp;#39;matching&amp;#39; to &amp;#39;simple&amp;#39;. To squelch this message and maintain the current behavior after the default changes, use: git config --global push.default matching To squelch this message and adopt the new behavior now, use: git config --global push.default simple This is collection of information gathered from Stackoverflow, Git docs and various internet sources. Putting it together so that I do not have to google it again.</description>
    </item>
    
    <item>
      <title>Installing and running &#39;naked&#39; hybris platform</title>
      <link>https://miroadamy.com/posts/2012-08-17-install-hybris/</link>
      <pubDate>Fri, 17 Aug 2012 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2012-08-17-install-hybris/</guid>
      <description>Installing and running &amp;ldquo;naked&amp;rdquo; hybris platform Log of an exercise to install and start the Hybris without all those fancy modules
Starting point: hybris-platform-4.7.1.zip
Install point: /opt/hybris-platform/hybris-platform-4.7.1
Start (with HSQLdb) ~ $ cd /opt/hybris-platform/hybris-platform-4.7.1 hybris-platform-4.7.1 $ cd bin/platform/ platform $ pwd /opt/hybris-platform/hybris-platform-4.7.1/bin/platform platform $ . ./setantenv.sh Setting ant home to: /opt/hybris-platform/hybris-platform-4.7.1/bin/platform/apache-ant-1.8.2 Apache Ant(TM) version 1.8.2 compiled on April 21 2011 platform $ ant clean all | tee ant-clean-all.log =&amp;gt; Select develop</description>
    </item>
    
    <item>
      <title>Gitolite Administration Guide</title>
      <link>https://miroadamy.com/posts/2012-08-06-gitilite-admin/</link>
      <pubDate>Mon, 06 Aug 2012 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2012-08-06-gitilite-admin/</guid>
      <description>How to setup new client You need to be pensieve admin to do this. You will have to login as service user (non-host account) and su to root.
 create new Linux user on pensieve setup gitolite:  git clone &amp;lt;git://github.com/sitaramc/gitolite&amp;gt; mkdir bin; export PATH=$PATH:~/bin gitolite/install -ln   add own public key to gitolite to get access to gilotile-admin repo (note the naming restrictions!!)  gitolite setup -pk miro.pub   get public key for the client account admin and add it (there can be multiple admins) clone the gitolite-admin repo from workstation whose pub key was added  git clone &amp;lt;client@pensieve.</description>
    </item>
    
    <item>
      <title>Using Gitolite for code sharing setup</title>
      <link>https://miroadamy.com/posts/2012-06-21-gitolite-setup/</link>
      <pubDate>Thu, 21 Jun 2012 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2012-06-21-gitolite-setup/</guid>
      <description>General setup of code sharing host The code sharing host (Pensieve) is dedicated Linux server in DMZ, accessible from external locations as well as from internal network (dual homed) - for the build server access.
Main features  multiple users each user represent a client:  e.g. users client1    Users are separated by Unix permissions:  access rights to /home/USER are 0700 - no access except the dedicated user only ThinkWrap has root access or sudo access the access via ssh for the user is blocked - the user client1 cannot log in using ssh and get shell, only use git to pull or push changes  Inside each user, there are multiple projects.</description>
    </item>
    
    <item>
      <title>Configuring permanent time updates for Linux</title>
      <link>https://miroadamy.com/posts/2011-02-03-linux-time/</link>
      <pubDate>Thu, 03 Feb 2011 11:22:48 +0800</pubDate>
      
      <guid>https://miroadamy.com/posts/2011-02-03-linux-time/</guid>
      <description>1) make sure the DNS works sudo vi /etc/resolv.conf cat /etc/resolv.conf nameserver 208.67.222.222 nameserver 208.67.220.220 nameserver 192.168.16.1 2) check that you have ntpd installed  cat /etc/ntp.conf
 3) make it work in all /sbin/chkconfig --list | grep ntpd sudo /sbin/chkconfig --level 2345 ntpd on 4) Initial sync  sudo /usr/sbin/ntpdate pool.ntp.org
 5) Start service / restart  sudo /sbin/service ntpd start
 </description>
    </item>
    
    <item>
      <title>Unit testing debt</title>
      <link>https://miroadamy.com/posts/2008-05-19-unit-testing-debt/</link>
      <pubDate>Mon, 19 May 2008 23:44:17 -0400</pubDate>
      
      <guid>https://miroadamy.com/posts/2008-05-19-unit-testing-debt/</guid>
      <description>I had the pleasure to listen very interesting podcast where Scott Hanselman and Quetzal Bradley discussed unit testing named &#34;Testing after Unit Tests&#34;. To increase the Google Karma of the information discussed I have decided to rehash and sum up few main ideas of this discussion.
Quetzal introduced the idea of &#34;negative coverage&#34; - meaning that if you have 88 % test coverage, you should not see this as something positive you have achieved, but as something missing (you miss 12 % of completion) - thus the title of this post.</description>
    </item>
    
  </channel>
</rss>